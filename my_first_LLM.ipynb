{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEv/CUCXdO0PySq5orRVj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ribeiroPM/meu-primeiro-LLM-com-Google-Gemini/blob/main/my_first_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando a biblioteca do Gemini"
      ],
      "metadata": {
        "id": "F3pzgLuwQw4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google.generativeai"
      ],
      "metadata": {
        "id": "wEvjOg_hQwQF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando as libs necessarias"
      ],
      "metadata": {
        "id": "_vFkhEVSQfYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Nth5rZSTQUEI"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pegando sua chave do banco de dados do colab"
      ],
      "metadata": {
        "id": "8Sx5mmMcRaJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get(\"SECRET_KEY\")\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "G5inE15fQpdO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações gerais do modelo"
      ],
      "metadata": {
        "id": "panMeLsnR2ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_settings ={\n",
        "        \"candidate_count\": 1,\n",
        "        \"temperature\": 0.5\n",
        "    }"
      ],
      "metadata": {
        "id": "H7AkHk7jR643"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações de \"politicamente correto\" do modelo"
      ],
      "metadata": {
        "id": "zvhFDU96STbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_setings = {\n",
        "      \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "      \"HATE\": \"BLOCK_NONE\",\n",
        "      \"SEXUAL\": \"BLOCK_NONE\"\n",
        " }"
      ],
      "metadata": {
        "id": "WvWFguYFSaEH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listando as versões possíveis para uso"
      ],
      "metadata": {
        "id": "Qc1mjuKnSsPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if \"generateContent\" in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "lvhSkf09SqZW",
        "outputId": "9a8a01c8-9369-4134-8fde-9339ae62c7a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo o modelo a ser usado e suas configurações"
      ],
      "metadata": {
        "id": "UE3sMoaRTCN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_settings,\n",
        "                              safety_settings=safety_setings)"
      ],
      "metadata": {
        "id": "iMr5XFRMS_l1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando para ver se tudo deu certo"
      ],
      "metadata": {
        "id": "13JF-8gGUSiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Quantas palavras um modelo de linguagem como voce consegue processar por segundo?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "OPkYtDHQUWKK",
        "outputId": "9131a317-0a92-434a-b811-88d4df9ef50b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Como um modelo de linguagem de IA, não processamento palavras por segundo no mesmo sentido que os computadores. Em vez disso, sou treinado em um vasto conjunto de dados de texto e uso técnicas de aprendizado de máquina para entender e gerar linguagem humana.\n",
            "\n",
            "Minha velocidade de processamento depende de vários fatores, incluindo:\n",
            "\n",
            "* **Tamanho e complexidade do texto:** Textos mais longos e complexos levam mais tempo para processar.\n",
            "* **Tarefa:** Tarefas diferentes, como geração de texto ou tradução, têm requisitos de processamento diferentes.\n",
            "* **Recursos computacionais:** A quantidade de poder de computação disponível afeta minha velocidade de processamento.\n",
            "\n",
            "Em geral, posso processar grandes quantidades de texto rapidamente, permitindo-me realizar tarefas de processamento de linguagem natural em tempo real.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando um chat para interagir com o Gemini, essa opcão de chat armazena o histórico"
      ],
      "metadata": {
        "id": "0tWnpjROT8oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])\n",
        "\n",
        "prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(f\"Resposta: {response.text}\\n\")\n",
        "  prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "4l1XW1HSUCX3",
        "outputId": "dc30fd84-807f-4825-9996-5f92c577823f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esperando prompt: Quantos gigabytes seriam necessarios para guardar todos os filmes já feitos até hoje\n",
            "Resposta: É impossível estimar com precisão o número de gigabytes necessários para armazenar todos os filmes já feitos até hoje devido a vários fatores:\n",
            "\n",
            "* **Número de filmes:** O número exato de filmes já feitos é desconhecido, pois há filmes antigos perdidos e filmes independentes e amadores que podem não ser contabilizados.\n",
            "* **Tamanho do arquivo:** O tamanho do arquivo de um filme varia dependendo da resolução, duração, taxa de quadros e formato de codificação.\n",
            "* **Qualidade do filme:** Filmes mais antigos podem ter qualidade inferior e, portanto, arquivos menores, enquanto filmes modernos têm resoluções e taxas de quadros mais altas, resultando em arquivos maiores.\n",
            "\n",
            "No entanto, podemos fazer uma estimativa aproximada com base nas seguintes suposições:\n",
            "\n",
            "* **Número de filmes:** 500.000 filmes (incluindo filmes perdidos e independentes)\n",
            "* **Tamanho médio do arquivo:** 10 gigabytes por filme (para filmes de qualidade média)\n",
            "\n",
            "Com essas suposições, o número total de gigabytes necessários seria:\n",
            "\n",
            "**500.000 filmes x 10 gigabytes/filme = 5.000.000 gigabytes**\n",
            "\n",
            "Portanto, seriam necessários aproximadamente **5 petabytes** para armazenar todos os filmes já feitos até hoje, com base nessas suposições. No entanto, é importante observar que este é apenas um número aproximado e o tamanho real do arquivo pode variar significativamente.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}